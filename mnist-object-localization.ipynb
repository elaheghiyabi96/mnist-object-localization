{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 46s 22ms/step - loss: 0.1277 - classification_loss: 0.1263 - bbox_loss: 0.0029 - classification_accuracy: 0.9624 - val_loss: 0.0463 - val_classification_loss: 0.0458 - val_bbox_loss: 9.8421e-04 - val_classification_accuracy: 0.9847\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0431 - classification_loss: 0.0428 - bbox_loss: 5.7610e-04 - classification_accuracy: 0.9862 - val_loss: 0.0385 - val_classification_loss: 0.0383 - val_bbox_loss: 3.9468e-04 - val_classification_accuracy: 0.9867\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0306 - classification_loss: 0.0304 - bbox_loss: 2.5504e-04 - classification_accuracy: 0.9907 - val_loss: 0.0327 - val_classification_loss: 0.0327 - val_bbox_loss: 1.6308e-04 - val_classification_accuracy: 0.9897\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0210 - classification_loss: 0.0209 - bbox_loss: 1.1189e-04 - classification_accuracy: 0.9934 - val_loss: 0.0309 - val_classification_loss: 0.0309 - val_bbox_loss: 6.7227e-05 - val_classification_accuracy: 0.9899\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0170 - classification_loss: 0.0170 - bbox_loss: 3.3527e-05 - classification_accuracy: 0.9946 - val_loss: 0.0402 - val_classification_loss: 0.0402 - val_bbox_loss: 1.2144e-05 - val_classification_accuracy: 0.9880\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "Predicted digit: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# 1. Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()  # Load MNIST dataset\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0  # Normalize and reshape training data\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0    # Normalize and reshape test data\n",
    "\n",
    "# 2. Generate synthetic bounding boxes for all images\n",
    "bbox_train = np.array([[6, 6, 22, 22] for _ in range(len(x_train))], dtype=np.float32) / 28.0  # Bounding box for training set\n",
    "bbox_test = np.array([[6, 6, 22, 22] for _ in range(len(x_test))], dtype=np.float32) / 28.0    # Bounding box for test set\n",
    "\n",
    "# 3. Define the CNN model with two outputs (classification and bounding box prediction)\n",
    "inputs = Input(shape=(28, 28, 1))                      # Input layer for 28x28 grayscale image\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)      # First convolutional layer\n",
    "x = MaxPooling2D((2, 2))(x)                            # First max-pooling layer\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)           # Second convolutional layer\n",
    "x = MaxPooling2D((2, 2))(x)                            # Second max-pooling layer\n",
    "x = Flatten()(x)                                       # Flatten the output\n",
    "x = Dense(128, activation='relu')(x)                   # Fully connected layer\n",
    "\n",
    "classification_output = Dense(10, activation='softmax', name='classification')(x)  # Output layer for digit classification\n",
    "bbox_output = Dense(4, activation='sigmoid', name='bbox')(x)                       # Output layer for bounding box prediction\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[classification_output, bbox_output])        # Create the model with two outputs\n",
    "\n",
    "# 4. Compile and train the model\n",
    "model.compile(\n",
    "    optimizer='adam',  # Optimizer\n",
    "    loss={'classification': 'sparse_categorical_crossentropy', 'bbox': 'mse'},  # Loss functions\n",
    "    loss_weights={'classification': 1.0, 'bbox': 0.5},  # Relative weights for each output\n",
    "    metrics={'classification': 'accuracy'}  # Evaluation metric\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    {'classification': y_train, 'bbox': bbox_train},  # Training labels for both outputs\n",
    "    epochs=5,  # Number of training epochs\n",
    "    validation_data=(x_test, {'classification': y_test, 'bbox': bbox_test})  # Validation data\n",
    ")\n",
    "\n",
    "# 5. Save the trained model to a file\n",
    "model.save('multi_output_mnist_model.h5')  # Save the entire model\n",
    "\n",
    "# 6. Test the model on a single image\n",
    "test_image = x_test[0:1]                            # Select one test image\n",
    "class_pred, bbox_pred = model.predict(test_image)  # Predict class and bounding box\n",
    "digit = np.argmax(class_pred[0])                   # Get the predicted digit\n",
    "bbox = bbox_pred[0] * 28                            # Convert normalized bbox to pixel values\n",
    "\n",
    "print(f\"Predicted digit: {digit}\")                  # Print predicted digit\n",
    "\n",
    "# Plot the image and the predicted bounding box\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(test_image[0].reshape(28, 28), cmap='gray')  # Show image in grayscale\n",
    "rect = patches.Rectangle(\n",
    "    (bbox[0], bbox[1]),          # Top-left corner of the box\n",
    "    bbox[2] - bbox[0],           # Width of the box\n",
    "    bbox[3] - bbox[1],           # Height of the box\n",
    "    linewidth=2, edgecolor='r', facecolor='none'  # Red box with no fill\n",
    ")\n",
    "ax.add_patch(rect)  # Add the bounding box to the plot\n",
    "plt.show()          # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
